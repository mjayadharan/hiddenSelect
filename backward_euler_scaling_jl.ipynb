{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41fed95-5cbc-439a-ad7e-7ae84dcfca25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_function (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "using DifferentialEquations\n",
    "using Optim\n",
    "using Plots\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) Define Lotka-Volterra ODE\n",
    "# ---------------------------------------------------------------\n",
    "# We'll treat (alpha, beta, gamma, delta) as parameters\n",
    "function lotka_volterra!(du, u, p, t)\n",
    "    alpha, beta, gamma, delta = p\n",
    "    x, z = u\n",
    "    du[1] = alpha*x - beta*x*z      # dx/dt\n",
    "    du[2] = delta*x*z - gamma*z     # dz/dt\n",
    "end\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2) Generate \"true\" data with a standard solver (fine or adaptive)\n",
    "# ---------------------------------------------------------------\n",
    "function generate_data(alpha_true, beta_true, gamma_true, delta_true, tdata, y0; noise_std=0.01)\n",
    "    # p = (alpha, beta, gamma, delta)\n",
    "    p = (alpha_true, beta_true, gamma_true, delta_true)\n",
    "    prob = ODEProblem(lotka_volterra!, y0, (tdata[1], tdata[end]), p)\n",
    "\n",
    "    # Solve adaptively with low tolerances, then sample solution at tdata\n",
    "    sol = solve(prob, Tsit5(); reltol=1e-8, abstol=1e-8)\n",
    "    y_clean = [sol(ti) for ti in tdata]  # each element is a 2D state\n",
    "\n",
    "    # Convert to matrix for convenience\n",
    "    y_clean_mat = hcat(y_clean...)'  # shape (length(tdata), 2)\n",
    "\n",
    "    # Add noise\n",
    "    y_noisy = y_clean_mat .+ noise_std .* randn.() .* ones(size(y_clean_mat))\n",
    "    return y_noisy\n",
    "end\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Fixed-step Euler integrator (we specify the number of points)\n",
    "# ---------------------------------------------------------------\n",
    "function euler_integration(p, t0, tf, y0, n_points)\n",
    "    # p: tuple of parameters (alpha, beta, gamma, delta)\n",
    "    # n_points in time => dt = (tf - t0) / (n_points - 1)\n",
    "    dt = (tf - t0)/(n_points - 1)\n",
    "    t_sol = range(t0, tf, length=n_points)\n",
    "    dim = length(y0)\n",
    "    y_sol = zeros(n_points, dim)\n",
    "    y_sol[1, :] = y0\n",
    "\n",
    "    for i in 1:(n_points-1)\n",
    "        # Forward Euler: u_{i+1} = u_i + dt * f(t_i, u_i)\n",
    "        t_i = t_sol[i]\n",
    "        x_i = y_sol[i, :]\n",
    "        # Evaluate ODE:\n",
    "        du = similar(x_i)\n",
    "        lotka_volterra!(du, x_i, p, t_i)\n",
    "        y_sol[i+1, :] = x_i .+ dt .* du\n",
    "    end\n",
    "\n",
    "    return collect(t_sol), y_sol\n",
    "end\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4) Define cost function (sum of squared errors) for parameter fitting\n",
    "#    No interpolation: we assume t_data matches an index subset in t_euler\n",
    "#    or we do nearest index. Below we'll do nearest index for general case.\n",
    "# ---------------------------------------------------------------\n",
    "function cost_function(params, t_data, data, y0, n_euler_points)\n",
    "    alpha_est, beta_est, gamma_est, delta_est = params\n",
    "    p_est = (alpha_est, beta_est, gamma_est, delta_est)\n",
    "\n",
    "    t0, tf = first(t_data), last(t_data)\n",
    "    t_eul, y_eul = euler_integration(p_est, t0, tf, y0, n_euler_points)\n",
    "\n",
    "    residual_sum = 0.0\n",
    "    for i in eachindex(t_data)\n",
    "        t_i = t_data[i]\n",
    "        # Find nearest index in t_eul\n",
    "        idx = findmin(abs.(t_eul .- t_i))[2]\n",
    "        residual_sum += sum((y_eul[idx, :] .- data[i, :]).^2)\n",
    "    end\n",
    "    return residual_sum\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edea81a-9b39-49d7-ad9f-4a4ab91a383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### n_euler = 20 ###\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching reset!(::SimulatedAnnealing{typeof(Optim.default_neighbor!), typeof(Optim.log_temperature)}, ::Optim.SimulatedAnnealingState{Vector{Float64}, Float64}, ::Optim.BarrierWrapper{OnceDifferentiable{Float64, Vector{Float64}, Vector{Float64}}, Optim.BoxBarrier{Vector{Float64}, Vector{Int64}}, Float64, Float64, Vector{Float64}}, ::Vector{Float64})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  reset!(::Any, \u001b[91m::Optim.GradientDescentState\u001b[39m, ::Any, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mOptim\u001b[39m \u001b[90m~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/first_order/\u001b[39m\u001b[90m\u001b[4mgradient_descent.jl:46\u001b[24m\u001b[39m\n\u001b[0m  reset!(::Any, \u001b[91m::Optim.BFGSState\u001b[39m, ::Any, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mOptim\u001b[39m \u001b[90m~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/first_order/\u001b[39m\u001b[90m\u001b[4mbfgs.jl:69\u001b[24m\u001b[39m\n\u001b[0m  reset!(::Any, \u001b[91m::Optim.LBFGSState\u001b[39m, ::Any, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mOptim\u001b[39m \u001b[90m~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/first_order/\u001b[39m\u001b[90m\u001b[4ml_bfgs.jl:151\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::SimulatedAnnealing{typeof(Optim.default_neighbor!), typeof(Optim.log_temperature)}, ::Optim.SimulatedAnnealingState{Vector{Float64}, Float64}, ::Optim.BarrierWrapper{OnceDifferentiable{Float64, Vector{Float64}, Vector{Float64}}, Optim.BoxBarrier{Vector{Float64}, Vector{Int64}}, Float64, Float64, Vector{Float64}}, ::Vector{Float64})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  reset!(::Any, \u001b[91m::Optim.GradientDescentState\u001b[39m, ::Any, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mOptim\u001b[39m \u001b[90m~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/first_order/\u001b[39m\u001b[90m\u001b[4mgradient_descent.jl:46\u001b[24m\u001b[39m\n\u001b[0m  reset!(::Any, \u001b[91m::Optim.BFGSState\u001b[39m, ::Any, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mOptim\u001b[39m \u001b[90m~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/first_order/\u001b[39m\u001b[90m\u001b[4mbfgs.jl:69\u001b[24m\u001b[39m\n\u001b[0m  reset!(::Any, \u001b[91m::Optim.LBFGSState\u001b[39m, ::Any, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mOptim\u001b[39m \u001b[90m~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/first_order/\u001b[39m\u001b[90m\u001b[4ml_bfgs.jl:151\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] optimize(df::OnceDifferentiable{Float64, Vector{Float64}, Vector{Float64}}, l::Vector{Float64}, u::Vector{Int64}, initial_x::Vector{Float64}, F::Fminbox{SimulatedAnnealing{typeof(Optim.default_neighbor!), typeof(Optim.log_temperature)}, Float64, Optim.var\"#51#53\"}, options::Optim.Options{Float64, Nothing})",
      "   @ Optim ~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/constrained/fminbox.jl:388",
      " [2] optimize(f::Function, l::Vector{Float64}, u::Vector{Int64}, initial_x::Vector{Float64}, F::Fminbox{SimulatedAnnealing{typeof(Optim.default_neighbor!), typeof(Optim.log_temperature)}, Float64, Optim.var\"#51#53\"}, options::Optim.Options{Float64, Nothing}; inplace::Bool, autodiff::Symbol)",
      "   @ Optim ~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/constrained/fminbox.jl:269",
      " [3] optimize(f::Function, l::Vector{Float64}, u::Vector{Int64}, initial_x::Vector{Float64}, F::Fminbox{SimulatedAnnealing{typeof(Optim.default_neighbor!), typeof(Optim.log_temperature)}, Float64, Optim.var\"#51#53\"}, options::Optim.Options{Float64, Nothing})",
      "   @ Optim ~/.julia/packages/Optim/HvjCd/src/multivariate/solvers/constrained/fminbox.jl:259",
      " [4] top-level scope",
      "   @ In[4]:59"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 5) Demonstration of the entire pipeline\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# True parameters\n",
    "true_params = [1.0, 0.1, 0.5, 0.05]\n",
    "\n",
    "alpha_true, beta_true, gamma_true, delta_true = true_params\n",
    "\n",
    "# We'll have 20 data points, from t=0..19\n",
    "n_data = 50\n",
    "t_data = range(0, 19, length=n_data)\n",
    "\n",
    "# Initial condition\n",
    "y0 = [30, 9]\n",
    "\n",
    "# Generate noisy data\n",
    "data_noisy = generate_data(alpha_true, beta_true, gamma_true, delta_true,\n",
    "                           collect(t_data), y0; noise_std=0.0)\n",
    "\n",
    "# List of Euler points to test\n",
    "euler_points_list = [20, 40, 60, 80, 100, 200]\n",
    "\n",
    "# We'll store the \"best\" result for each n_euler (lowest cost among 20 seeds)\n",
    "best_params_dict = Dict{Int,Tuple{Float64,Float64,Float64,Float64}}()\n",
    "best_cost_dict   = Dict{Int,Float64}()\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# For each n_euler, do 20 random seeds -> pick the best\n",
    "# -----------------------------------------------------------\n",
    "for n_euler in euler_points_list\n",
    "    println(\"\\n### n_euler = $n_euler ###\")\n",
    "\n",
    "    best_cost = Inf\n",
    "    best_params = (0.0, 0.0, 0.0, 0.0)\n",
    "\n",
    "    for trial in 1:100\n",
    "        # Use a different random seed each trial\n",
    "        Random.seed!(trial)\n",
    "\n",
    "        # We'll pick an initial guess randomly near (1, 0.5, 0.8, 0.3)\n",
    "        # Or you can pick any strategy\n",
    "        init_guess = [max(0.001,alpha_true + 0.1*randn()), max(0.001,beta_true + 0.1*randn()),\n",
    "                      max(0.001,gamma_true + 0.1*randn()), max(0.001,delta_true + 0.1*randn())]\n",
    "\n",
    "        # We'll do an unconstrained optimization using Optim\n",
    "        # cost_function(...) expects a vector for `params`\n",
    "        f_to_min(x) = cost_function(x, collect(t_data), data_noisy, y0, n_euler)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # We can use e.g. Nelder-Mead or BFGS\n",
    "        lower_bounds = fill(0.0, length(init_guess))\n",
    "        upper_bounds = fill(500, length(init_guess))  # No upper bound (positive values only)\n",
    "        opts = Optim.Options(iterations=1000)\n",
    "        # res = optimize(f_to_min, init_guess, NelderMead(), opts)\n",
    "        # res = optimize(f_to_min, lower_bounds, upper_bounds, init_guess, Fminbox(NelderMead()), opts)\n",
    "        res = optimize(f_to_min, lower_bounds, upper_bounds, init_guess, Fminbox(SimulatedAnnealing()), opts)\n",
    "        \n",
    "        # res = optimize(f_to_min, lower_bounds, upper_bounds, init_guess, Fminbox(BFGS()), opts)\n",
    "        \n",
    "\n",
    "        \n",
    "        this_cost = Optim.minimum(res)\n",
    "        this_params = Optim.minimizer(res)\n",
    "\n",
    "        # println(\"Trial $trial => cost=$this_cost, params=$(this_params)\")\n",
    "\n",
    "        if this_cost < best_cost\n",
    "            best_cost = this_cost\n",
    "            best_params = (this_params[1], this_params[2], this_params[3], this_params[4])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    println(\"Best cost for n_euler=$n_euler is $best_cost with params $best_params\")\n",
    "    best_params_dict[n_euler] = best_params\n",
    "    best_cost_dict[n_euler]   = best_cost\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6) Plot only the best (lowest cost) solution for each n_euler\n",
    "# -----------------------------------------------------------\n",
    "nplots = length(euler_points_list)\n",
    "plt = plot(layout=(1,nplots), size=(1200,400), legend=:best)\n",
    "\n",
    " # n_data_sim = 100\n",
    " #        t_sim = np.linspace(0, 19, n_data_sim)  # from 0 to 19 (inclusive)\n",
    "        \n",
    " #        # ---------------------------------------------------------------\n",
    " #        # Generate synthetic \"true\" data\n",
    " #        # (Using solve_ivp with small tolerances as a 'standard solver')\n",
    " #        # ---------------------------------------------------------------\n",
    " #        print(\"readhed her\")\n",
    " #        y_sim = generate_data(a_est, b_est, g_est, d_est,\n",
    " #                           t_sim, y0, noise_std=0)\n",
    "\n",
    "\n",
    "for (i, n_euler) in enumerate(euler_points_list)\n",
    "    t_best_sim = LinRange(0, 19, 400)\n",
    "    t_best_sim_range = range(0, 19, length=400)\n",
    "    \n",
    "    y_best_sim = generate_data(best_params_dict[n_euler][1], best_params_dict[n_euler][2], best_params_dict[n_euler][3],\n",
    "        best_params_dict[n_euler][4], collect(t_best_sim_range), y0; noise_std=0.0)\n",
    "    p_est = best_params_dict[n_euler]\n",
    "    # t_eul, y_eul = euler_integration(p_est, 0.0, 19.0, y0, n_euler)\n",
    "\n",
    "    plot!(plt[i], t_data, data_noisy[:,1], seriestype=:scatter,\n",
    "          marker=:circle, label=\"Data x\", alpha=0.7)\n",
    "    plot!(plt[i], t_data, data_noisy[:,2], seriestype=:scatter,\n",
    "          marker=:diamond, label=\"Data z\", alpha=0.7)\n",
    "    plot!(plt[i], t_best_sim, y_best_sim[:,1], label=\"Euler x\")\n",
    "    plot!(plt[i], t_best_sim, y_best_sim[:,2], label=\"Euler z\")\n",
    "    title!(plt[i], \"n_euler = $n_euler (best run)\")\n",
    "    xlabel!(plt[i], \"Time\")\n",
    "    ylabel!(plt[i], \"Population\")\n",
    "end\n",
    "\n",
    "display(plt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f62177e-9b9c-446f-84bc-c4b118c6a662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400×2 Matrix{Float64}:\n",
       " 1.0       0.5\n",
       " 1.02855   0.500083\n",
       " 1.05791   0.500495\n",
       " 1.08809   0.501245\n",
       " 1.11908   0.502346\n",
       " 1.15091   0.503808\n",
       " 1.18358   0.505644\n",
       " 1.21708   0.507868\n",
       " 1.25142   0.510495\n",
       " 1.28661   0.513541\n",
       " 1.32262   0.517022\n",
       " 1.35947   0.520958\n",
       " 1.39714   0.525368\n",
       " ⋮         \n",
       " 0.420299  0.648209\n",
       " 0.430088  0.639705\n",
       " 0.440237  0.631456\n",
       " 0.450755  0.623459\n",
       " 0.461654  0.615714\n",
       " 0.472945  0.608217\n",
       " 0.48464   0.600969\n",
       " 0.49675   0.593968\n",
       " 0.509287  0.587212\n",
       " 0.522264  0.580701\n",
       " 0.535694  0.574435\n",
       " 0.54959   0.568412"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    t_best_sim = range(0, 19, length=400)\n",
    "\n",
    "generate_data(best_params_dict[20][1], best_params_dict[20][2], best_params_dict[20][3],\n",
    "        best_params_dict[20][4], collect(t_best_sim), y0; noise_std=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54ba042b-f965-4727-8241-21bf15acf191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b755bd2f-80e2-4775-afd6-9693e5515b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756c321a-3841-4c62-b46c-d6cc54766ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c,d,e,f = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914bd4c3-9be4-4b21-a860-aefd6bfffcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
